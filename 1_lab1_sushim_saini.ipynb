{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ac4272",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Key exists and begins with AIzaSyBE...\n",
            "The USA has **\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "## from guides.community_contributions.lab1_sanjayfuloria_solution import question\n",
        "load_dotenv(override=True)\n",
        "\n",
        "import os\n",
        "# Use GOOGLE_API_KEY for Gemini, with fallback to OPENAI_API_KEY if you only have one key in .env\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"OPENAI_API_KEY\")\n",
        "if google_api_key:\n",
        "    print(f\"API Key exists and begins with {google_api_key[:8]}...\")\n",
        "else:\n",
        "    print(\"API Key not set - set GOOGLE_API_KEY or OPENAI_API_KEY in .env (see guides folder)\")\n",
        "\n",
        "# from openai import OpenAI\n",
        "# openai_client = OpenAI(api_key=openai_api_key)\n",
        "# response = openai_client.chat.completions.create(\n",
        "#     model=\"gpt-4o-mini\",\n",
        "#     messages=messages,\n",
        "#     temperature=0.5,\n",
        "#     max_tokens=100,\n",
        "# )\n",
        "#from google import genai\n",
        "#from google.genai import types\n",
        "\n",
        "#google_client = genai.Client(api_key=google_api_key)\n",
        "#messages = [\"how many state USA has ?\"]  # Gemini accepts a list of strings (or a single string)\n",
        "#config = types.GenerateContentConfig(\n",
        "#    temperature=0.5,\n",
        "#    max_output_tokens=100,\n",
        "#)\n",
        "# Try gemini-2.0-flash first; if quota exceeded (429), fall back to gemini-1.5-flash\n",
        "#last_error = None\n",
        "#  for model_name in [\"gemini-2.5-flash\", \"gemini-1.5-flash\"]:\n",
        "#    try:\n",
        "#        response = google_client.models.generate_content(\n",
        "#            model=model_name,\n",
        "#            contents=messages,\n",
        "#            config=config,\n",
        "#        )\n",
        "#        print(response.text)\n",
        "#        break\n",
        "#    except Exception as e:\n",
        "#        last_error = e\n",
        "#        if \"429\" in str(e) or \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "#            print(f\"Quota exceeded for {model_name}, trying next model...\")\n",
        "#            continue\n",
        "#        raise\n",
        "#else:\n",
        "#    if last_error:\n",
        "#        raise last_error\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
